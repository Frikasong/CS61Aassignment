{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Frikasong/CS61Aassignment/blob/main/Module2_assignment_w26.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module 2: Assignment"
      ],
      "metadata": {
        "id": "eFCArjxeHuR8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instructions**\n",
        "\n",
        "You should begin by viewing Lesson 2 on eClass (and note that the lesson includes a link to the notebook used in the videos).\n",
        "\n",
        "Next, everyone should attempt to complete the beginner and intermediate sections of this assignment. If you are interested you can continue to advanced. Whether you choose to go beyond the beginner and intermediate sections will not affect your participation grade, but some of the skills you learn (or relearn) may be helpful for your final project for the course.\n",
        "\n",
        "In addition, everyone should complete the final reflection section.\n",
        "\n",
        "Combined, the lesson and assignment should not take you more than three hours -- so if you get to that point, just move on to the reflective section (and add a text/markdown cell to the notebook indicating where you stopped and saying that you hit the 3 hour limit).\n",
        "\n",
        "When you have finished, upload a copy of the .ipynb file to eClass assignment page.\n",
        "\n",
        "NOTE: If you are using Colab and you downloaded this file by clicking a link, make sure to save a copy of this file on your Google Drive by selecting File, Save."
      ],
      "metadata": {
        "id": "MxZsmxPBH-Q1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Beginner Question 1:\n",
        "\n",
        "Create a text file called courses.txt with the names of each of the courses that you are taking this year (each course on one line)."
      ],
      "metadata": {
        "id": "XZwaYTu8IGOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "courses = [\"legal info technology\\n\",\"tax for enterpirses \\n\",\"trusts\\n\", \"admin law\\n\"]\n",
        "f = open('courses.txt','w')\n",
        "f.writelines(courses)\n",
        "f.close() # Close the file after writing\n",
        "f = open('courses.txt','r') # Reopen the file in read mode\n",
        "print (f.read())\n",
        "f.close() # Close the file after reading"
      ],
      "metadata": {
        "id": "Eq60bwrDWQGe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "739a1d70-de40-4174-e6b9-cf03b32caf13"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "legal info technology\n",
            "tax for enterpirses \n",
            "trusts\n",
            "admin law\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Beginner Question 2:\n",
        "\n",
        "Find a course summary (yours or one that you find online) for an Osgoode Hall Law School course in MS Word docx format.\n",
        "\n",
        "Extract the text of the document into a variable called: course_summary\n",
        "\n",
        "Print the first 20 characters of each of the first 20 paragraphs of the course_summary variable"
      ],
      "metadata": {
        "id": "Ca5ARYegWQ_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx\n",
        "from docx import Document\n",
        "from google.colab import files\n",
        "\n",
        "upload = files.upload()\n",
        "uploaded_filename = list(upload.keys())[0]\n",
        "doc = Document(uploaded_filename)\n",
        "course_summary = [paragraph.text for paragraph in doc.paragraphs]\n",
        "for paragraph in course_summary[:20]:\n",
        "  print(paragraph[:20])"
      ],
      "metadata": {
        "id": "0wyzhXh7ovTQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "outputId": "1690d0d2-4568-404b-a022-84344f8b3ad2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (6.0.2)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (4.15.0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-138d80b7-d05d-47aa-8696-f3019227cdc8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-138d80b7-d05d-47aa-8696-f3019227cdc8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Property Law.docx to Property Law (2).docx\n",
            "Property Short Summa\n",
            "\n",
            "The properties of pr\n",
            "Justifications for p\n",
            "Novel claims……………………\n",
            "Sources of Canadian \n",
            "Property in perspect\n",
            "Possession…………………………\n",
            "Adverse possession (\n",
            "Finders…………………………………\n",
            "Gifts………………………………………\n",
            "Common law estates……\n",
            "Leasgites & licences\n",
            "Co-ownership……………………\n",
            "Bailment………………………………\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Beginner Question 3:\n",
        "\n",
        "Create a pandas dataframe using data about refugee claims decided in 2019 available at: https://refugeelab.ca/wp-content/uploads/2024/06/2019_RPD_Data.xlsx\n",
        "\n",
        "Using the dataframe, list the 10 counsel who worked on the largest number of refugee claims in 2019."
      ],
      "metadata": {
        "id": "Jvp-e9yOQeiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel('https://refugeelab.ca/wp-content/uploads/2024/06/2019_RPD_Data.xlsx')\n",
        "print(\"Available columns:\", df.columns.tolist())\n",
        "\n",
        "top_counsels = df['Counsel Fullname'].value_counts().head(10)\n",
        "print(\"Top 10 counsels who worked on the largest number of refugee claims:\\n\",top_counsels)"
      ],
      "metadata": {
        "id": "BvNrJhqXRcfF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de0d7f4b-537c-4cbe-e118-4f5a681ae444"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Available columns: ['IRB file no', 'Date Referred', 'Decision Date', 'Date Decision Mailed', 'Explanation', 'Language of Record', 'Minister Counsel Participation Type', 'Member Fullname', 'Country Persecution', 'Associated File Number', 'Counsel Fullname']\n",
            "Top 10 counsels who worked on the largest number of refugee claims:\n",
            " Counsel Fullname\n",
            "CINTOSUN, BRIAN IBRAHIM    285\n",
            "Singer, Melissa            269\n",
            "Siryuyumusi, Pacifique     240\n",
            "Desjardins, Odette         177\n",
            "GRICE, JOHN W              170\n",
            "VALOIS, Stéphanie          170\n",
            "MARKAKI, STYLIANI          164\n",
            "IVANYI, PETER              162\n",
            "LOEBACH, MICHAEL           160\n",
            "HAMILTON, IAN              158\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Intermediate Question 1:\n",
        "\n",
        "Using the same dataframe about refugee claims in 2019 from Beginner Question 3, filter the dataframe so that it only includes positive and negative decisions (excluding claims that were otherwise resolved, such as claims that were abandoned).\n",
        "\n",
        "Using the filtered dataframe, caculate and print the grant rates for the ten highest volume counsel, listed from highest grant rate to lowest grant rate."
      ],
      "metadata": {
        "id": "szBeP6bzXXGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel('https://refugeelab.ca/wp-content/uploads/2024/06/2019_RPD_Data.xlsx')\n",
        "print(\"Available columns:\", df.columns.tolist())\n",
        "\n",
        "df_filtered = df[df['Explanation'].isin(['Positive', 'Negative'])]\n",
        "counsel_volume_filtered = df_filtered['Counsel Fullname'].value_counts()\n",
        "top_10_counsel_names = counsel_volume_filtered.head(10).index\n",
        "df_top_counsel = df_filtered[df_filtered['Counsel Fullname'].isin(top_10_counsel_names)]\n",
        "\n",
        "total_decisions_per_counsel = df_top_counsel['Counsel Fullname'].value_counts()\n",
        "positive_decisions_per_counsel = df_top_counsel[df_top_counsel['Explanation'] == 'Positive']['Counsel Fullname'].value_counts()\n",
        "\n",
        "grant_rates = (positive_decisions_per_counsel / total_decisions_per_counsel).fillna(0) * 100\n",
        "grant_rates_sorted = grant_rates.sort_values(ascending=False)\n",
        "print(\"\\nGrant rates for the ten highest volume counsel:\\n\", grant_rates_sorted)"
      ],
      "metadata": {
        "id": "0JrZyf9wOb3M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a10807b-be44-46c9-bbc7-5386c8521ed9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Available columns: ['IRB file no', 'Date Referred', 'Decision Date', 'Date Decision Mailed', 'Explanation', 'Language of Record', 'Minister Counsel Participation Type', 'Member Fullname', 'Country Persecution', 'Associated File Number', 'Counsel Fullname']\n",
            "\n",
            "Grant rates for the ten highest volume counsel:\n",
            " Counsel Fullname\n",
            "TATHAM, MARY               92.307692\n",
            "CINTOSUN, BRIAN IBRAHIM    90.322581\n",
            "HAMILTON, IAN              86.000000\n",
            "KORMAN, MICHAEL            71.755725\n",
            "LOEBACH, MICHAEL           68.000000\n",
            "VALOIS, Stéphanie          66.935484\n",
            "GRICE, JOHN W              63.333333\n",
            "Singer, Melissa            51.336898\n",
            "KABATERAINE, NKUNDA        46.721311\n",
            "MENGHILE, Claudette        40.517241\n",
            "Name: count, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Intermediate Question 2:\n",
        "\n",
        "The lesson videos show you how to engage with the Refugee Law Lab's Bulk Decisions Dataset using [Hugging Face Datasets](https://huggingface.co/datasets/refugee-law-lab/canadian-legal-data).\n",
        "\n",
        "In 2025, responsibility for this dataset was transfered to [Access to Algorithmic Justice](https://a2aj.ca). The A2AJ dataset works largely the same way, although there are different fields.\n",
        "\n",
        "Review the documentation for the A2AJ datasets [here](https://huggingface.co/datasets/a2aj/canadian-case-law) and [here](https://github.com/a2aj-ca/canadian-legal-data).\n",
        "\n",
        "Download the Ontario Court of Appeal dataset, convert it to a pandas dataframe. Then print the citation and name of the case for the most recent decision in that dataframe.\n"
      ],
      "metadata": {
        "id": "pf2UXletSIQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install requests\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "\n",
        "cases = load_dataset(\"a2aj/canadian-case-law\", data_dir=\"ONCA\", split=\"train\")\n",
        "df = cases.to_pandas()\n",
        "print(\"Available columns:\", df.columns.tolist())\n",
        "\n",
        "df['date'] = pd.to_datetime(df['document_date_en'])\n",
        "df_sorted = df[df['date'].notna()].sort_values(by='date', ascending = True)\n",
        "most_recent = df_sorted.iloc[-1]\n",
        "\n",
        "print(\"Most Recent Decisions:\")\n",
        "print(\"Citation:\", most_recent['citation_en'])\n",
        "print(\"Case Name:\", most_recent['name_en'])\n",
        "print(\"Date:\", most_recent['document_date_en'])"
      ],
      "metadata": {
        "id": "OQKLzSJWhg6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ba2ee2a-0a1f-4984-b215-d4adf1858f18"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2026.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2026.1.4)\n",
            "Available columns: ['dataset', 'citation_en', 'citation2_en', 'name_en', 'document_date_en', 'url_en', 'scraped_timestamp_en', 'unofficial_text_en', 'citation_fr', 'citation2_fr', 'name_fr', 'document_date_fr', 'url_fr', 'scraped_timestamp_fr', 'unofficial_text_fr', 'upstream_license']\n",
            "Most Recent Decisions:\n",
            "Citation: 2026 ONCA 18\n",
            "Case Name: R. v. C.L.\n",
            "Date: 2026-01-16 00:00:00+00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Intermediate Question 3:\n",
        "\n",
        "In addition to bulk downloads, the A2AJ also makes its data available via an Application Programming Interface. Review documentation about using that API [here](https://github.com/a2aj-ca/canadian-legal-data/blob/main/access-via-api.ipynb).\n",
        "\n",
        "Using the API, programmatically download the text of section 167 of the Immigration and Refugee Protection Act and print it."
      ],
      "metadata": {
        "id": "Hr4g6bKchkAH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZpdRUKkBmqTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Advanced Question 1:\n",
        "\n",
        "Scrape the biographies of all judges on the Ontario Court of Appeal's [website](https://www.ontariocourts.ca/coa/judges-of-the-court/), and put them into a dataframe that includes the name of the judge, the text of the judge's biography, the URL where the biography is found, and the date/time when you scraped the biography\n"
      ],
      "metadata": {
        "id": "vuRR79MLmreY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P5UOlpRGAPvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reflection\n",
        "\n",
        "If you could work with any legal data programmatically what data would you like to have access to?\n",
        "\n",
        "Does that data currently exist in a publicly accessible format that can be easily integrated into Python programs?\n",
        "\n",
        "If not, why not?"
      ],
      "metadata": {
        "id": "B1dB6sivAgx6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wZsK_nMhBTTL"
      }
    }
  ]
}