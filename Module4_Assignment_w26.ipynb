{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Frikasong/CS61Aassignment/blob/main/Module4_Assignment_w26.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85tFfNSWCBEr"
      },
      "source": [
        "# Module 4 Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTEZLIGnCBEr"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "You should begin by viewing Lesson 4 on eClass (and note that the lesson includes a link to the notebook used in the videos).\n",
        "\n",
        "Next, everyone should attempt to complete the beginner and intermediate sections of this assignment. If you are interested you can continue to advanced. Whether you choose to go beyond the beginner and intermediate sections will not affect your participation grade, but some of the skills you learn (or relearn) may be helpful for your final project for the course.\n",
        "\n",
        "In addition, everyone should complete the sections marked as for \"Everyone\".\n",
        "\n",
        "Combined, the lesson and assignment should not take you more than three hours -- so if you get to that point, just move on to the \"Everyone\" sections (and add a text/markdown cell to the notebook indicating where you stopped and saying that you hit the 3 hour limit).\n",
        "\n",
        "When you have finished, upload a copy of the .ipynb file to eClass assignment page.\n",
        "\n",
        "NOTE: If you are using Colab and you downloaded this file by clicking a link, make sure to save a copy of this file on your Google Drive by selecting File, Save."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahACM1auCBEr"
      },
      "source": [
        "### Everyone (if you are using OpenAI):\n",
        "\n",
        "Log into the OpenAI [platform](https://platform.openai.com/).\n",
        "\n",
        "Click on \"Billing\". Ensure that you have a positive balance (add $5 if you do not -- and recall that if that poses a barrier for you, please request a grant from the Refugee Law Lab). Then, confirm that auto recharge is set to off.\n",
        "\n",
        "Next, click on \"Limits\". Add a budget (e.g. $5) and an email altert. In addition to setting the budget limits, the same page will also show you the rate limits that apply to your account. These will show you: which models you have access to, the number of tokens that you are allowed to send per minute, and the number of requests that you are able to send per minute. The consequence of going beyond the rate limits is just that the system will respond with an error message.\n",
        "\n",
        "You can find additional information about pricing [here](https://openai.com/api/pricing/) and about rate limits [here](https://platform.openai.com/docs/guides/rate-limits). Note that the API does not have a monthly fee. You only pay for usage. The assignment for this module can be completed for (far) less than the $5 minimum credits.\n",
        "\n",
        "Once you have confirmed that you have set budget limits and auto recharge is off, indicate that in the markup cell below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6Ixeka1CBEs"
      },
      "source": [
        "I have set budget limit as $5 and auto recharge is off."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lT60ZWuHCBEs"
      },
      "source": [
        "### Beginner Question 1\n",
        "\n",
        "Go to OpenAI's platform (log in and select API) here:\n",
        "\n",
        "https://platform.openai.com/playground\n",
        "\n",
        "Select responses mode.\n",
        "\n",
        "Try asking the system a legal question that arises from one of your other courses. See how the answer compares using different models. See if anything changes when you change the system message. See if anything changes when you change other parameters.\n",
        "\n",
        "Based on this experimentation, if you wanted to use the system to help answer questions from your courses, what settings and system message would you use and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQBFLw28CBEs"
      },
      "source": [
        "I choose to use gpt4.1-mini or nano, after balancing the price and output. I have tested gpt 5.2, 5.2nano, and gpt 4.1, 4.1 mini, and nano, with same question: give me the leading cases in distinguishing ABI and AAII in ITA under Canadian Tax Law, 5.2 nano fails to comprehend the abbreviation, while the 4.1 models have a great response overall, and 4.1 nano is the most cost efficient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p46AzhB0CBEs"
      },
      "source": [
        "### Beginner Question 2\n",
        "\n",
        "Using the best settings you were able to come up with in the playground select one example of a legal question and use Python to:\n",
        "\n",
        "(a) print the number of input tokens in the example\n",
        "\n",
        "(b) calculate and print the cost of sending those input tokens to the OpenAI api\n",
        "\n",
        "(c) send the example (using the settings that you used in the playground for Beginner Question 2) to the OpenAI api and print the result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "z3iWVuKfCBEs",
        "outputId": "ef15adaf-a3fb-444d-fa0b-9a0cd43d62fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.16.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.12.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2025.11.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2026.1.4)\n",
            "[a] Number of input tokens: 37\n",
            "[b] Estimated input cost: $0.000004 USD\n",
            "    (Based on $0.1/1M tokens for gpt-4.1-nano)\n",
            "\n",
            "[c] API Response:\n",
            "--------------------------------------------------\n",
            "Under common law, the key elements required to establish a valid contract are as follows:\n",
            "\n",
            "1. **Offer**: One party must present a clear and definite proposal to enter into an agreement, indicating their willingness to be bound by specific terms.\n",
            "\n",
            "2. **Acceptance**: The other party must agree to the terms of the offer unequivocally and unequivocally, signifying their consent to be bound by those terms.\n",
            "\n",
            "3. **Consideration**: There must be something of value exchanged between the parties—such as money, goods, services, or a promise—to demonstrate mutual intent and create a binding obligation.\n",
            "\n",
            "4. **Mutual Intent to Contract (Meeting of the Minds)**: Both parties must have a shared understanding and agreement on the essential terms and the nature of the contract.\n",
            "\n",
            "5. **Legal Capacity**: The parties involved must have the legal ability to enter into a contract, meaning they are of legal age and of sound mind.\n",
            "\n",
            "6. **Legality of Purpose**: The contract’s purpose must be lawful; contracts involving illegal activities are not enforceable.\n",
            "\n",
            "These elements collectively ensure that a contract is valid, enforceable, and reflects the genuine agreement of the parties involved.\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install --upgrade tiktoken\n",
        "\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "import tiktoken\n",
        "\n",
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_KEY')\n",
        "\n",
        "client = OpenAI()\n",
        "MODEL = \"gpt-4.1-nano\"\n",
        "TEMPERATURE = 0.7\n",
        "MAX_TOKENS = 500\n",
        "\n",
        "LEGAL_QUESTION = \"\"\"You are a helpful legal assistant. Answer the following question:\n",
        "\n",
        "What are the key elements required to establish a valid contract under common law?\n",
        "Please provide a brief overview of each element.\"\"\"\n",
        "\n",
        "# --- (a) Count and print input tokens ---\n",
        "\n",
        "def count_tokens(text, model):\n",
        "    encoding = tiktoken.get_encoding(\"o200k_base\")\n",
        "    num_tokens = len(encoding.encode(text))\n",
        "    return num_tokens\n",
        "num_input_tokens = count_tokens(LEGAL_QUESTION, MODEL)\n",
        "\n",
        "print(f\"[a] Number of input tokens: {num_input_tokens}\")\n",
        "\n",
        "# --- (b) Calculate and print the cost of input tokens ---\n",
        "# Pricing (as of Feb 2026)\n",
        "# gpt-4.1 nano is 0.10 USD for 1M input tokens\n",
        "INPUT_COST_PER_1M = 0.10  # USD\n",
        "\n",
        "cost = (num_input_tokens / 1_000_000) * INPUT_COST_PER_1M\n",
        "print(f\"[b] Estimated input cost: ${cost:.6f} USD\")\n",
        "print(f\"    (Based on ${INPUT_COST_PER_1M}/1M tokens for {MODEL})\")\n",
        "\n",
        "# --- (c) Send to OpenAI API and print the result ---\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": LEGAL_QUESTION}],\n",
        "    temperature=TEMPERATURE,\n",
        "    max_tokens=MAX_TOKENS,\n",
        ")\n",
        "print(f\"\\n[c] API Response:\\n{'-'*50}\")\n",
        "print(response.choices[0].message.content)\n",
        "print(f\"{'-'*50}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Beginner Question 3\n",
        "\n",
        "Choose a Supreme Court of Canada case that you read for a class recently.\n",
        "\n",
        "Load the A2AJ Hugging Face Dataset for the Supreme Court.\n",
        "\n",
        "Extract the text of the case from that dataset.\n",
        "\n",
        "Using the OpenAI API and the text of the case, ask generative AI to prepare a case brief for a law student taking the specific course that you read the case for, using the best system / user message and parameters that you're able to craft.\n",
        "\n",
        "Print out the name of the case, the citation, and the generative AI case brief.\n",
        "\n",
        "How does the case brief compare to one that you might write?"
      ],
      "metadata": {
        "id": "FqVOvsgMwoza"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T3MkEKw2wmr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEYhOSgGCBEt"
      },
      "source": [
        "### Intermediate Question 1\n",
        "\n",
        "The Ontario Ministry of Labour maintains a database of collective agreements: https://ws.lr.labour.gov.on.ca/CA/doc\n",
        "\n",
        "Find 5 recent collective agreements.\n",
        "\n",
        "For each collective agreement, print out the name of parties to the collective agreement and a generative AI summary of pay increases.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubrGx22dCBEs"
      },
      "source": [
        "### Intermediate Question 2\n",
        "\n",
        "Using the dataset with SCC judge bios that can be loaded using the code below, use gernative ai to extract the judges' province of origin (if in bio), put the results in the dataframe, and print a bar chart with the number of judges per province.\n",
        "\n",
        "HINT: To reduce cost and increase speed, use a smaller model like gpt 5 nano, use low reasoning, and test on a small subsets of the dataframe to ensure it is working properly before you run it on all the judges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_hJYaZXCBEs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/srehaag/legal_info_tech_w26/main/judges.json\"\n",
        "df = pd.read_json(url)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p1Da0j10t6oX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBNDrBbhCBEs"
      },
      "source": [
        "### Advanced Question 1\n",
        "\n",
        "[Legal Bench](https://hazyresearch.stanford.edu/legalbench/) is a project by several legal academics and computer scientists to create datasets and benchmarks for legal tasks completed by generative AI systems.\n",
        "\n",
        "One of the [tasks](https://hazyresearch.stanford.edu/legalbench/tasks/canada_tax_court_outcomes.html) involves categorizing outcomes from the text of Tax Court of Canada decisions.\n",
        "\n",
        "Using the best prompts and parameters that you're able to craft, test the accuracy of an OpenAI model (use a relatively small and cheap model) on 50 examples from that task.\n",
        "\n",
        "What accuracy rates do you get?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXoReM1tCBEt"
      },
      "source": [
        "### Everyone Question:\n",
        "\n",
        "Comment on something that you found interesting or challenging in completing this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDpuJUt_CBEt"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}